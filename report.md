# ポリゴンSIMA処理 途中クラッシュの原因と対応

## 事象

- **単点CSV（中心抽出）**: LAZ解凍＋フィルタリングは最後まで完走する。
- **ポリゴンSIMA**: LAZ解凍＋3領域分類は、約3,000万点付近で「Render process gone」となりタブがクラッシュする（2.7億点規模のLAZで再現）。

## 原因

| 処理 | メモリに保持するデータ | 結果 |
|------|------------------------|------|
| 単点CSV | フィルタに**通った点だけ**を配列に push | 点数が少なくメモリは小さい |
| ポリゴンSIMA（対応前） | **全点**を `points.push(p)` で配列に保持 | 2.7億個のJSオブジェクト → 数GB〜数十GBでOOM |

ポリゴンSIMAでは「全点に内側/帯/外側の分類を付けてLASで出力」するため、従来は解凍した全点を `points` 配列に蓄えていた。点数が億単位になると、オブジェクト数とプロパティ分のメモリが膨大になり、レンダラがクラッシュしていた。

## 対応内容

ポリゴンSIMAのLAZ経路のみ、**点の配列を一切持たず**「解凍ストリームの各点をその場でLAS用バッファに書き込み、チャンク単位でBlobにまとめる」方式に変更した。

### 1. ストリーミング解凍＋その場書き込み

- 解凍は `decompressLAZStreaming` で1点ずつ取得。
- 各点で内側/帯/外側を判定し、Classification と帯のマゼンタ色を設定。
- その点を**配列に push せず**、現在の出力チャンク（52MB の ArrayBuffer）の該当オフセットに直接書き込む。チャンクが満杯になったら次のチャンクを確保し、配列 `pointChunks` に push。

### 2. チャンク＋Blob による出力（ArrayBuffer 2GB 制限の回避）

- 2.7億点×26バイト ≈ 6.5GB の **1本の ArrayBuffer** はブラウザの上限（多くは約2GB）を超えるため、採用していない。
- 定数 `POLYGON_STREAM_CHUNK_BYTES = 52 * 1024 * 1024`（52MB、点レコード長の倍数）。1チャンクあたり約200万点。
- ストリーム終了後: ヘッダー用 227 バイトの ArrayBuffer を確保し、`buildLASHeaderForStreamedOutput` で書き込み。`outputLasBuffer = new Blob([headerBuf, ...pointChunks], ...)` でダウンロード用 Blob を生成。
- ダウンロード・結果表示では `outputLasBuffer`（Blob）をそのまま `URL.createObjectURL` と `blob.size` で使用。

### 3. 追加した関数・定数

- `LAS_HEADER_SIZE = 227`
- `POLYGON_STREAM_CHUNK_BYTES` … ポリゴンストリーミング出力の1チャンクサイズ（52MB）。
- `writeSinglePointToLASView(view, offset, point, pointRecordLength, hasRGB, originX, originY, originZ)` … 1点をLAS点レコードとして DataView に書き込む。
- `buildLASHeaderForStreamedOutput(view, pointCount, pointFormat, pointRecordLength, firstPoint, minX, maxX, ...)` … ストリーム完了後にLASヘッダー（227バイト）を書き込む。

### 4. decompressLAZStreaming の変更

- コールバックを `onPoint(point, pointIndex)` に拡張（第2引数に通し番号を渡す）。既存の中心抽出などは `(point) => ...` のまま利用可能。

### 5. メモリ

- 解凍中: 圧縮入力バッファ ＋ laz-perf の作業用のみ。
- 出力: 点の配列は持たず、**同時に保持するのは「現在の1チャンク（52MB）＋ヘッダー用227バイト＋完了済みチャンク配列」**。最終成果物は Blob で 1 つの LAS としてダウンロード可能。

これにより、2.7億点規模でも「2.7億個のオブジェクト配列」も「6.5GBの単一 ArrayBuffer」も経由せず、単点CSVと同様にメモリを抑えて完走し、1つの LAS ファイルとしてダウンロードできる。

- **立面図LAZ**: 共通ヘルパー `streamLAZToLASBlob` を導入し、LAZ経路もストリーミング解凍＋その場でLAS書き出しに統一。1GB級LAZでもメモリを抑えて完了する。スフィア点は `extraPoints` で末尾に追加。

## 処理できる最大サイズ

コード上に「この点数まで」という**ハードな上限は設けていない**。どこまで処理できるかは次の要因で決まる。

### ポリゴンSIMA（LAZ・ストリーミング出力）

- **主な制約はメモリ**。
  - **入力**: LAZ を `arrayBuffer` で一括読むため、圧縮ファイル全体がメモリに載る。
  - **出力**: 点データを 52MB チャンクに分けて保持し、完了済みチャンクをすべて `pointChunks` に保持するため、**全チャンクが同時にメモリに残る**。
- 目安（1点26バイト・約200万点/チャンク）:
  - 2.7億点 → 約135チャンク → 出力用に約 **7GB**。
  - これに**圧縮LAZのサイズ**と laz-perf の作業領域が加わる。
- 実質的な上限は「（利用可能なRAM − 圧縮ファイルサイズ − 数百MB）÷ 52MB × 約200万点」に近い。例: 実質8GBなら2.7億点前後、16GBなら **5〜6億点程度** まで現実的。

### 単点CSV（中心抽出）

- 全点は保持せず「フィルタ通過分だけ」を配列に入れるため、点数制限は緩い。
- 制約になるのは**圧縮LAZを一括読む**ため「圧縮ファイルサイズが利用可能メモリ内」であることと、処理時間。

### その他

- **1個の ArrayBuffer**: 多くのブラウザで約2GBまで。52MBチャンクなので問題にならない。
- **点数のインデックス**: ループ変数などは JavaScript の number（整数は 2^53 まで安全）のため、数十億点レベルまでは番号的な上限はない。
- **Blob／ダウンロード**: 仕様上の点数上限はないが、数GB超のファイルではブラウザやOSのダウンロードまわりで挙動が変わる可能性はある。

| 処理 | 制約の中心 | 2.7億点で必要な目安 |
|------|-------------|----------------------|
| ポリゴンSIMA（LAZ） | 出力チャンク合計＋圧縮LAZ | 約8〜10GB RAM |
| 単点CSV（LAZ） | 圧縮LAZの一括読込 | 圧縮ファイルサイズ分 |

## 処理効率（速度・安定性）の改善

### 実施済み: 外側ポリゴンの AABB で早期除外

- 毎点で `pointInPolygon` を 2 回（内側・外側）呼んでいると、2.7億点で約 5.4億回の ray casting になる。
- **外側ポリゴンの軸平行バウンディングボックス（AABB）** を事前に 1 回だけ計算し、各点で「bbox の外なら即 outside」とするようにした。
- ポリゴンが点群範囲に比べて小さい場合、大半の点が bbox 外で 1 回の判定（4 比較）で終わるため、**分類処理の高速化**が期待できる。
- 追加: `getPolygonBBox(polygon)`、`classifyPointForPolygon(..., outerBBox)` の第4引数。

### 実施済み: 点オブジェクトの再利用と進捗間隔の延長

- **点オブジェクトの再利用**: `decompressLAZStreaming` 内で、毎点ごとに `{ x, y, z, intensity, ... }` を新規作成していた（2.7億点なら2.7億オブジェクト）。**1個の点オブジェクトをループ外で確保し、中身だけ上書きしてコールバックに渡す**ように変更。ポリゴン経路では点を配列に積まないためそのまま利用可能。中心抽出・`loadLAZAsPointsStreaming` では「採用した点だけ」コピーして push するようにし、参照の共有を防いだ。GC 負荷が減り、処理時間短縮と安定化が期待できる。
- **進捗間隔のオプション**: `decompressLAZStreaming` に `opts.progressInterval` を追加（未指定時は従来どおり 500 万点）。必要に応じて呼び出し側で大きくすると処理は速くなるが、進捗表示は 500 万点間隔のまま運用している。

### その他の改善の余地

| 項目 | 内容 |
|------|------|
| **進捗の yield 間隔** | さらに大きくする（例: 2,000万点）と処理はさらに速くなるが、UI の応答が鈍る。トレードオフ。 |
| **Web Worker** | 解凍＋分類を Worker に移すとメインスレッドがブロックされず、タブの「フリーズ」感が減る。laz-perf の WASM を Worker で動かす実装が必要。 |
| **出力チャンクのメモリ** | 全チャンクを保持してから Blob にしているため、点数が極端に多いと RAM が増える。ストリーミングでダウンロードだけ先に開始する方式は、対応が重い。 |
| **pointInPolygon のさらなる最適化** | 現状は ray casting のまま。ポリゴンが凸なら別アルゴリズムも検討できるが、SIMA は一般多角形のため効果は限定的。 |

## CloudCompare で表示されない問題（出力 LAS の raw 座標がすべて 0）

good.las（表示できる）と trouble.las（表示できない）を `compare_laz_structure.py` で比較したところ、**trouble 側は全点の raw X,Y,Z が 0** になっており、world 座標がすべてヘッダー Offset と同一になっていた。

**原因**: 解凍ストリームで**点オブジェクトを 1 個だけ再利用**しており、`firstPoint = p` で**参照**を入れていた。ループの次の反復で `p` が 2 点目で上書きされると `firstPoint` も同じオブジェクトのため上書きされ、`originX = firstPoint.x` が常に「現在の点」の x になる。その結果 `(p.x - originX) === 0` となり、**全点の raw が 0** で書き込まれていた。

**修正**: 先頭点の座標を**値で保持**するように変更。`firstPoint = p` の代わりに `firstPoint = { x: p.x, y: p.y, z: p.z }` とし、以降の origin はこのオブジェクトを参照する。これで 2 点目以降も正しい raw（先頭点との差分）が書き込まれる。

## 補足

- 非圧縮LASのポリゴン経路（ストリーミング／一括読込）は従来どおり「全点を配列に読んでから分類」のまま。
- エラー履歴: 当初は「全点配列」を廃止して「1本の ArrayBuffer に直接書き込み」にしたが、処理開始直後に `RangeError: Array buffer allocation failed` が発生。上記のチャンク＋Blob 方式に変更して解消。

## 変更ファイル

- `app_github_pages.js` … ストリーミング書き込みロジック・ヘルパー・ポリゴンLAZ経路のチャンク＋Blob 出力への差し替え。
